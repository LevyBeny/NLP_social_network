{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load tweets\n",
    "social_networks = [\"pinterest\", \"facebook\", \"instagram\", \"tumblr\", \"linkedin\"]\n",
    "tweets_dict = {network: [] for network in social_networks}\n",
    "for network in social_networks:\n",
    "    with open('./collections/' + network + '.json', mode='r') as f:\n",
    "        network_tweets = []\n",
    "        for line in f:\n",
    "            network_tweets.append(json.loads(line))\n",
    "    for tweet in network_tweets:\n",
    "        tweets_dict[network].append(tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144180"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_dict['tumblr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "arr = []\n",
    "for network in tweets_dict:\n",
    "    for i, tweet in enumerate(tweets_dict[network]):\n",
    "        text = tweet['text']\n",
    "        is_rt = text.startswith(\"RT\")\n",
    "        row = {'user': tweet['user']['id_str'],\n",
    "               'text': text,\n",
    "               'network': network,\n",
    "               'is_rt': is_rt}\n",
    "        arr.append(row)\n",
    "\n",
    "df = pd.DataFrame(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_network = df.groupby(by='network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook 40995 10191 30804 482\n",
      "instagram 37194 8026 29168 500\n",
      "linkedin 60042 24724 35318 823\n",
      "pinterest 301050 47122 253928 841\n",
      "tumblr 144180 60244 83936 877\n"
     ]
    }
   ],
   "source": [
    " \n",
    "for name,group in by_network:\n",
    "    print(name, len(group),len(group[group['is_rt']==False].index),\n",
    "          len(group[group['is_rt']==True].index), len(np.unique(group['user'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_is_rt = df.groupby(by='is_rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### No RT #######\n",
      "pinterest 763 90.72532699167658\n",
      "facebook 309 64.10788381742739\n",
      "instagram 405 81.0\n",
      "tumblr 699 79.70353477765109\n",
      "linkedin 751 91.25151883353584\n",
      "###### Only RT #######\n",
      "pinterest 646 76.81331747919144\n",
      "facebook 407 84.43983402489627\n",
      "instagram 338 67.6\n",
      "tumblr 791 90.19384264538198\n",
      "linkedin 471 57.22964763061968\n"
     ]
    }
   ],
   "source": [
    "# Print num of distinct users per network with not RT\n",
    "for is_rt, group in by_is_rt:\n",
    "    if not is_rt:\n",
    "        print('###### No RT #######')\n",
    "        for network in social_networks:\n",
    "            totsl_num_users = len(np.unique(df[df['network']==network]['user']))\n",
    "            num_users = len(np.unique(group[group['network']==network]['user']))\n",
    "            print(network, num_users, 100*num_users/totsl_num_users)\n",
    "    else:\n",
    "        print('###### Only RT #######')\n",
    "        for network in social_networks:\n",
    "            totsl_num_users = len(np.unique(df[df['network']==network]['user']))\n",
    "            num_users = len(np.unique(group[group['network']==network]['user']))\n",
    "            print(network, num_users, 100*num_users/totsl_num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x431793518>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot hist of number of tweets per users for each network - No RT\n",
    "for network, data in by_network:\n",
    "    no_rt = data[data['is_rt']==False]\n",
    "    arr_count = [] \n",
    "    for user, user_data in no_rt.groupby(by='user'):\n",
    "        user_count = user_data.shape[0]\n",
    "        row = {'user':user,'user_count_'+network : user_count}\n",
    "        arr_count.append(row)\n",
    "    df_users_counts = pd.DataFrame(arr_count)\n",
    "    df_users_counts.hist(column='user_count_'+network, bins=1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network\tAvg_num_tweets_for_user (SD)\t max\n",
      "facebook\t32.980582524271846(78.08227101531983)\t720\n",
      "[270 419 481 676 720]\n",
      "instagram\t19.817283950617284(55.945883883332044)\t555\n",
      "[233 339 375 544 555]\n",
      "linkedin\t32.92143808255659(81.62559751024158)\t1526\n",
      "[ 421  461  508  539 1526]\n",
      "pinterest\t61.758846657929226(103.83094201018416)\t1004\n",
      "[ 615  739  924  960 1004]\n",
      "tumblr\t86.1859799713877(167.4541161188806)\t2936\n",
      "[ 751  815 1090 1230 2936]\n"
     ]
    }
   ],
   "source": [
    "# Avg num of tweets per user for each network - No RT\n",
    "print(\"Network\\tAvg_num_tweets_for_user (SD)\\t max\")\n",
    "for network, data in by_network:\n",
    "    no_rt = data[data['is_rt']==False]\n",
    "    arr_count = [] \n",
    "    for user, user_data in no_rt.groupby(by='user'):\n",
    "        arr_count.append(user_data.shape[0])\n",
    "    print('{}\\t{}({})\\t{}'.format(network,np.mean(arr_count),np.std(arr_count),np.max(arr_count)))\n",
    "    print(np.sort(arr_count)[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/benl/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "facebook\n",
      "neg:0.06403895594151701, neu:0.8097308409380827, pos:0.12623304876852126, compound:0.09981660288489844\n",
      "instagram\n",
      "neg:0.05940356341888862, neu:0.7905392474458012, pos:0.14993147271368054, compound:0.14671014203837526\n",
      "linkedin\n",
      "neg:0.04198365960200615, neu:0.8340328021355767, pos:0.12398167772205143, compound:0.15641838699239607\n",
      "pinterest\n",
      "neg:0.06529886252705742, neu:0.8122298289546284, pos:0.12247082042358133, compound:0.10080782437078223\n",
      "tumblr\n",
      "neg:0.07744006042095479, neu:0.77345418630901, pos:0.14894195272558264, compound:0.11238903293274019\n"
     ]
    }
   ],
   "source": [
    "# Sentiment with nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for network, data in by_network:\n",
    "    print(network)\n",
    "    no_rt = data[data['is_rt']==False]\n",
    "    polarity_dict = {'neg': [], 'neu': [], 'pos':[], 'compound':[]}\n",
    "    for i,tweet in no_rt.iterrows():\n",
    "        polarity = sid.polarity_scores(tweet['text'])\n",
    "        polarity_dict['neg'].append(polarity['neg'])\n",
    "        polarity_dict['neu'].append(polarity['neu'])\n",
    "        polarity_dict['pos'].append(polarity['pos'])\n",
    "        polarity_dict['compound'].append(polarity['compound'])\n",
    "    print ('neg:{}, neu:{}, pos:{}, compound:{}'.format(np.mean(polarity_dict['neg']),\n",
    "                                                        np.mean(polarity_dict['neu']),\n",
    "                                                        np.mean(polarity_dict['pos']),\n",
    "                                                        np.mean(polarity_dict['compound'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-07 17:26:48,067 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/TEXT-CLASSIFICATION_imdb/imdb.pt not found in cache, downloading to /var/folders/q7/926ntdp17c5_68cq17gzm7c80000gn/T/tmp2kfzeogr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1190022144/2794252905 [03:24<04:16, 6264333.05B/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-3d203cbf4bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mflair_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-sentiment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/nn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36m_fetch_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# File, and it exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unexpected EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1811\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Sentiment with flair\n",
    "\n",
    "import flair\n",
    "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
    "\n",
    "for network, data in by_network:\n",
    "    print(network)\n",
    "    no_rt = data[data['is_rt']==False]\n",
    "    polarity_dict = {'neg': [], 'neu': [], 'pos':[], 'compound':[]}\n",
    "    for i,tweet in no_rt.iterrows():\n",
    "        ben = 4\n",
    "s = flair.data.Sentence(tweet['text'])\n",
    "flair_sentiment.predict(s)\n",
    "total_sentiment = s.labels\n",
    "#         polarity_dict['neg'].append(polarity['neg'])\n",
    "#         polarity_dict['neu'].append(polarity['neu'])\n",
    "#         polarity_dict['pos'].append(polarity['pos'])\n",
    "#         polarity_dict['compound'].append(polarity['compound'])\n",
    "#     print ('neg:{}, neu:{}, pos:{}, compound:{}'.format(np.mean(polarity_dict['neg']),\n",
    "#                                                         np.mean(polarity_dict['neu']),\n",
    "#                                                         np.mean(polarity_dict['pos']),\n",
    "#                                                         np.mean(polarity_dict['compound'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for is_rt, group in by_is_rt:\n",
    "    if not is_rt:\n",
    "        group.to_csv('./no_rt_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
